{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nGiIgx6PQR_i"
   },
   "source": [
    "#Mask R-CNN instance segmentation with custom dataset in Google Colab\n",
    "Jupyter notebook providing steps to train a **Matterport Mask R-CNN** model with custom dataset.\n",
    "\n",
    "It runs in [Google Colab](https://colab.research.google.com/) using [Matterport framework](https://github.com/matterport/Mask_RCNN) with TensorFlow backend.\n",
    "\n",
    "**Requirements are only dataset images and annotations file.**\n",
    "\n",
    "**Colab Runtime type: Python3, GPU enabled.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "umEL6-vlmXmj"
   },
   "source": [
    "#Making Dataset\n",
    "I generated dataset annotations with [VGG Image Annotator](http://www.robots.ox.ac.uk/~vgg/software/via/).\n",
    "\n",
    "Notebook train a model for one class object detection. It is possible to slightly modify notebook to train model for multiple classes.\n",
    "\n",
    "Before running notebook, we need to create dataset:\n",
    "\n",
    "\n",
    "1.   Collect various pictures of objects to detect\n",
    "3.   Create annotation files in VGG\n",
    "4.   Create image.zip file having structure defined below\n",
    "5.   Upload the zip file in your Google Drive\n",
    "\n",
    "Zip file structure:\n",
    "```\n",
    "images.zip\n",
    "|- \"train\" directory\n",
    "  |- jpg image files of training data\n",
    "  |- \"via_region_data.json\" annotations file of training data\n",
    "|- \"val\" directory\n",
    "  |- jpg image files of validation data\n",
    "  |- \"via_region_data.json\" annotations file of validation data\n",
    "```\n",
    "Check my image.zip file as dataset example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ywU9FM5qn6Wx"
   },
   "source": [
    "#Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "39Wtm53bG7xW",
    "outputId": "a77016dd-a63b-4a60-e986-b761e96954a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root\n"
     ]
    }
   ],
   "source": [
    "# %cd\n",
    "  \n",
    "# !git clone --quiet https://github.com/richhosek/Mask_RCNN.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "GZY2h5buS9xb",
    "outputId": "67e95ee3-e117-473f-da9f-7269685e24a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing mask_rcnn.egg-info\\PKG-INFO\n",
      "writing dependency_links to mask_rcnn.egg-info\\dependency_links.txt\n",
      "writing top-level names to mask_rcnn.egg-info\\top_level.txt\n",
      "reading manifest file 'mask_rcnn.egg-info\\SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n",
      "writing manifest file 'mask_rcnn.egg-info\\SOURCES.txt'\n",
      "installing library code to build\\bdist.win-amd64\\egg\n",
      "running install_lib\n",
      "running build_py\n",
      "creating build\\bdist.win-amd64\\egg"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:<class 'Exception'>\n",
      "WARNING:root:Fail load requirements file, so using default ones.\n",
      "zip_safe flag not set; analyzing archive contents...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "creating build\\bdist.win-amd64\\egg\\mrcnn\n",
      "copying build\\lib\\mrcnn\\config.py -> build\\bdist.win-amd64\\egg\\mrcnn\n",
      "copying build\\lib\\mrcnn\\model copy.py -> build\\bdist.win-amd64\\egg\\mrcnn\n",
      "copying build\\lib\\mrcnn\\model.py -> build\\bdist.win-amd64\\egg\\mrcnn\n",
      "copying build\\lib\\mrcnn\\parallel_model.py -> build\\bdist.win-amd64\\egg\\mrcnn\n",
      "copying build\\lib\\mrcnn\\utils copy.py -> build\\bdist.win-amd64\\egg\\mrcnn\n",
      "copying build\\lib\\mrcnn\\utils.py -> build\\bdist.win-amd64\\egg\\mrcnn\n",
      "copying build\\lib\\mrcnn\\visualize.py -> build\\bdist.win-amd64\\egg\\mrcnn\n",
      "copying build\\lib\\mrcnn\\__init__.py -> build\\bdist.win-amd64\\egg\\mrcnn\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\mrcnn\\config.py to config.cpython-36.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\mrcnn\\model copy.py to model copy.cpython-36.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\mrcnn\\model.py to model.cpython-36.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\mrcnn\\parallel_model.py to parallel_model.cpython-36.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\mrcnn\\utils copy.py to utils copy.cpython-36.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\mrcnn\\utils.py to utils.cpython-36.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\mrcnn\\visualize.py to visualize.cpython-36.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\mrcnn\\__init__.py to __init__.cpython-36.pyc\n",
      "creating build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying mask_rcnn.egg-info\\PKG-INFO -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying mask_rcnn.egg-info\\SOURCES.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying mask_rcnn.egg-info\\dependency_links.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying mask_rcnn.egg-info\\top_level.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "creating 'dist\\mask_rcnn-2.1-py3.6.egg' and adding 'build\\bdist.win-amd64\\egg' to it\n",
      "removing 'build\\bdist.win-amd64\\egg' (and everything under it)\n",
      "Processing mask_rcnn-2.1-py3.6.egg\n",
      "Removing c:\\users\\richh\\.conda\\envs\\python 3-6\\lib\\site-packages\\mask_rcnn-2.1-py3.6.egg\n",
      "Copying mask_rcnn-2.1-py3.6.egg to c:\\users\\richh\\.conda\\envs\\python 3-6\\lib\\site-packages\n",
      "mask-rcnn 2.1 is already the active version in easy-install.pth\n",
      "\n",
      "Installed c:\\users\\richh\\.conda\\envs\\python 3-6\\lib\\site-packages\\mask_rcnn-2.1-py3.6.egg\n",
      "Processing dependencies for mask-rcnn==2.1\n",
      "Finished processing dependencies for mask-rcnn==2.1\n"
     ]
    }
   ],
   "source": [
    "# %cd ~/Mask_RCNN\n",
    "\n",
    "# !pip install -q PyDrive\n",
    "# !pip install -r requirements.txt\n",
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6zZg68_koGU7"
   },
   "source": [
    "#Download and extract dataset\n",
    "Update fileId variable with Google Drive id of your image.zip dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "p3KxhAII1PDT",
    "outputId": "e8e64f59-d00e-4acc-daaf-e81331fb5ca0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/Mask_RCNN\n"
     ]
    }
   ],
   "source": [
    "# %cd ~/Mask_RCNN\n",
    "\n",
    "\n",
    "# fileId = '1p11kagop07-LyNyTIQ5_bDHx6I2TSDN9'\n",
    "\n",
    "# import os\n",
    "# from zipfile import ZipFile\n",
    "# from shutil import copy\n",
    "# from pydrive.auth import GoogleAuth\n",
    "# from pydrive.drive import GoogleDrive\n",
    "# from google.colab import auth\n",
    "# from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# os.makedirs('dataset')\n",
    "# os.chdir('dataset')\n",
    "\n",
    "# auth.authenticate_user()\n",
    "# gauth = GoogleAuth()\n",
    "# gauth.credentials = GoogleCredentials.get_application_default()\n",
    "# drive = GoogleDrive(gauth)\n",
    "\n",
    "# fileName = fileId + '.zip'\n",
    "# downloaded = drive.CreateFile({'id': fileId})\n",
    "# downloaded.GetContentFile(fileName)\n",
    "# ds = ZipFile(fileName)\n",
    "# ds.extractall()\n",
    "# os.remove(fileName)\n",
    "# print('Extracted zip file ' + fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Hjjc40apLpd"
   },
   "source": [
    "#Edit settings file\n",
    "*  find and replace occurrences of \"balloon\" and \"Balloon\" with name of your object\n",
    "*  set epochs number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "0SVHFnl5Hwe3",
    "outputId": "6dd8aa49-17e3-4461-d2aa-885a50c1a35b"
   },
   "outputs": [],
   "source": [
    "# %cd ~/Mask_RCNN\n",
    "\n",
    "# !cp ~/Mask_RCNN/samples/balloon/balloon.py ./vehicle.py\n",
    "\n",
    "# !sed -i -- 's/balloon/vehicle/g' vehicle.py\n",
    "# !sed -i -- 's/Balloon/Vehicle/g' vehicle.py\n",
    "# !sed -i -- 's/epochs=30/epochs=5/g' vehicle.py\n",
    "# !pip uninstall protobuf\n",
    "# !pip uninstall tensorflow-gpu\n",
    "# !pip install tensorflow@1.13.2\n",
    "# !pip install tensorflow-gpu@1.13.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AjmxrVOwq0rC"
   },
   "source": [
    "#Train model\n",
    "Pretrained weights options are COCO, ImageNet or a model trained before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "EJGrimv2Xuf3",
    "outputId": "19080960-e94d-4b3e-ff82-262cfe3b6e76"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\richh\\.conda\\envs\\Python 3-6\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\richh\\.conda\\envs\\Python 3-6\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\richh\\.conda\\envs\\Python 3-6\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\richh\\.conda\\envs\\Python 3-6\\lib\\imp.py\", line 243, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\richh\\.conda\\envs\\Python 3-6\\lib\\imp.py\", line 343, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: The specified module could not be found.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"vehicle.py\", line 43, in <module>\n",
      "    from mrcnn import model as modellib, utils\n",
      "  File \"C:\\Users\\richh\\Documents\\GitHub\\Mask_RCNN\\mrcnn\\model.py\", line 19, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\richh\\.conda\\envs\\Python 3-6\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\n",
      "  File \"C:\\Users\\richh\\.conda\\envs\\Python 3-6\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow\n",
      "  File \"C:\\Users\\richh\\.conda\\envs\\Python 3-6\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
      "    raise ImportError(msg)\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\richh\\.conda\\envs\\Python 3-6\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\richh\\.conda\\envs\\Python 3-6\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\richh\\.conda\\envs\\Python 3-6\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\richh\\.conda\\envs\\Python 3-6\\lib\\imp.py\", line 243, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\richh\\.conda\\envs\\Python 3-6\\lib\\imp.py\", line 343, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: The specified module could not be found.\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "\n",
      "See https://www.tensorflow.org/install/errors\n",
      "\n",
      "for some common reasons and solutions.  Include the entire stack trace\n",
      "above this error message when asking for help.\n"
     ]
    }
   ],
   "source": [
    "# %cd ~/Mask_RCNN\n",
    "\n",
    "!python vehicle.py train --dataset=dataset/ --weights=coco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "laqF3Tihrqs3"
   },
   "source": [
    "#Run inference on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "colab_type": "code",
    "id": "2o7dH-mRX2A0",
    "outputId": "df6f33fb-576b-4b23-8625-d46531f57a06"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-942af8691d1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT_DIR\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# To find local version of the library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mcustom_WEIGHTS_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/logs/*/mask_rcnn_*.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import skimage\n",
    "import glob\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "import vehicle\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "\n",
    "custom_WEIGHTS_PATH = sorted(glob.glob(\"/logs/*/mask_rcnn_*.h5\"))[-1]\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "config = vehicle.VehicleConfig()\n",
    "custom_DIR = os.path.join(ROOT_DIR, \"dataset\")\n",
    "\n",
    "class InferenceConfig(config.__class__):\n",
    "    # Run detection on one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()\n",
    "\n",
    "# Device to load the neural network on.\n",
    "# Useful if you're training a model on the same \n",
    "# machine, in which case use CPU and leave the\n",
    "# GPU for training.\n",
    "DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "# Inspect the model in training or inference modes\n",
    "# values: 'inference' or 'training'\n",
    "# TODO: code for 'training' test mode not ready yet\n",
    "TEST_MODE = \"inference\"\n",
    "\n",
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax\n",
    "  \n",
    "# Load validation dataset\n",
    "dataset = vehicle.VehicleDataset()\n",
    "dataset.load_vehicle(custom_DIR, \"val\")\n",
    "\n",
    "# Must call before using the dataset\n",
    "dataset.prepare()\n",
    "\n",
    "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))\n",
    "\n",
    "# Create model in inference mode\n",
    "with tf.device(DEVICE):\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n",
    "                              config=config)\n",
    "\n",
    "# load the last model you trained\n",
    "# weights_path = model.find_last()[1]\n",
    "\n",
    "# Load weights\n",
    "print(\"Loading weights \", custom_WEIGHTS_PATH)\n",
    "model.load_weights(custom_WEIGHTS_PATH, by_name=True)\n",
    "\n",
    "from importlib import reload # was constantly changin the visualization, so I decided to reload it instead of notebook\n",
    "reload(visualize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X7iSzccTL9hM"
   },
   "outputs": [],
   "source": [
    "#image_id = random.choice(dataset.image_ids)\n",
    "for image_id in dataset.image_ids:\n",
    "  image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "      modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n",
    "  info = dataset.image_info[image_id]\n",
    "  print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id, \n",
    "                                         dataset.image_reference(image_id)))\n",
    "\n",
    "  # Run object detection\n",
    "  results = model.detect([image], verbose=1)\n",
    "\n",
    "  # Display results\n",
    "  ax = get_ax(1)\n",
    "  r = results[0]\n",
    "  visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                              dataset.class_names, r['scores'], ax=ax,\n",
    "                              title=\"Predictions\")\n",
    "  log(\"gt_class_id\", gt_class_id)\n",
    "  log(\"gt_bbox\", gt_bbox)\n",
    "  log(\"gt_mask\", gt_mask)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "6zZg68_koGU7",
    "4Hjjc40apLpd"
   ],
   "machine_shape": "hm",
   "name": "Copy of maskrcnn_custom_tf_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
